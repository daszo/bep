{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d66405",
   "metadata": {},
   "source": [
    "# Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38db753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mid', 'sender', 'eid', 'date', 'message_id', 'subject', 'body',\n",
       "       'folder', 'length_character', 'length_word', 'body_clean',\n",
       "       'clean_length_character', 'clean_length_word', 'similarities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = \"enron.db\"\n",
    "\n",
    "experiment = True\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "c = conn.cursor()\n",
    "\n",
    "if experiment:\n",
    "    sql_query = \"SELECT * FROM N10K\" \n",
    "else:\n",
    "    sql_query = \"SELECT * FROM N100K\" \n",
    "\n",
    "df = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c411b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import summarizer\n",
    "from summa import keywords\n",
    "\n",
    "def get_keywords_safe(text, num_words=8):\n",
    "    \"\"\"\n",
    "    Wrapper for summa.keywords to handle IndexError on short texts.\n",
    "    Summa throws an IndexError if the text has fewer tokens than 'words'.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    try:\n",
    "        # Summa returns a newline-separated string\n",
    "        kw_str = keywords.keywords(text, words=num_words)\n",
    "        return kw_str.split('\\n') if kw_str else []\n",
    "    except IndexError:\n",
    "        kw_str = keywords.keywords(text)\n",
    "        return kw_str.split('\\n') if kw_str else []\n",
    "    except Exception:\n",
    "        return text.split()\n",
    "\n",
    "def calculate_query_and_ed(row):\n",
    "    \n",
    "    # try: \n",
    "        text = f\"{row['subject']} \\n {row['body_clean']}\"\n",
    "\n",
    "        row['text_rank_query'] = summarizer.summarize(text, words=15) \n",
    "\n",
    "        # --- 2. Generate \"Elaborative Description\" (Keyword Extraction) ---\n",
    "        # We want a list of salient terms that describe the document content.\n",
    "        # This creates a \"bag of entities\" representation useful for GR.\n",
    "        # row['elaborative_description'] = keywords.keywords(text, words=8)\n",
    "        row['elaborative_description'] = get_keywords_safe(text, 8)\n",
    "        \n",
    "        return row\n",
    "    # except Exception:\n",
    "    #     print(row)\n",
    "    #     raise Exception\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d6585bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "QUERY\n",
      "Re: letter agreement between EES and Enron Corp.\n",
      "==========\n",
      "BODY\n",
      "Re: letter agreement between EES and Enron Corp.---------------------- Forwarded by Sara Shackleton/HOU/ECT on 03/31/2000 \n",
      "04:08 PM ---------------------------\n",
      "\n",
      "Sara and Gareth,\n",
      "We still need to finish this agreement and have it signed.  To my knowledge, \n",
      "it has not been completed and signed.\n",
      "David\n",
      "Enron Energy Services\n",
      "\n",
      "Sara,\n",
      "I'm on someone else's computer - I'm having all sorts of e-mail problems \n",
      "today.\n",
      "The business person on the  EES side to be signing this letter would be Mark \n",
      "S. Muller.  He is a Managing Director of EES LLC.\n",
      "I don't necessarily have a problem with the description of the back-to-back \n",
      "obligations, but I'd like to know Gareth's opinion as to whether the language \n",
      "is too broad.\n",
      "David\n",
      "Sara Shackleton@ECT\n",
      "03/30/2000 04:38 PM\n",
      "\n",
      "Attached is a first stab at the agreement.  Please comment.\n",
      "==========\n",
      "ED\n",
      "['letter agreement', 'business person', 'ees', 'llc', 'managing', 'director']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60944/2604911314.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['text_rank_query'] = summarizer.summarize(text, words=15)\n",
      "/tmp/ipykernel_60944/2604911314.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['text_rank_query'] = summarizer.summarize(text, words=15)\n",
      "/tmp/ipykernel_60944/2604911314.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['elaborative_description'] = keywords.keywords(text, words=8).split('\\n')\n",
      "/tmp/ipykernel_60944/2604911314.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row['elaborative_description'] = keywords.keywords(text, words=8).split('\\n')\n"
     ]
    }
   ],
   "source": [
    "row = calculate_query_and_ed(df.iloc[5])\n",
    "print('='*10)\n",
    "print('QUERY')\n",
    "print(row['text_rank_query'])\n",
    "print('='*10)\n",
    "print(\"BODY\")\n",
    "print(row['subject'] + row['body_clean'])\n",
    "print('='*10)\n",
    "print('ED')\n",
    "print(row['elaborative_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b6eb3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mid                     sender     eid        date  \\\n",
      "0     332279     daren.farmer@enron.com  332114  24/02/2000   \n",
      "1     466418      carol.clair@enron.com  466022  22/07/2000   \n",
      "2     153571    chris.germany@enron.com  151808  08/05/2000   \n",
      "3     489653  kimberly.watson@enron.com  488916  14/08/2001   \n",
      "4     281696     leann.walton@enron.com  278851  09/11/2001   \n",
      "...      ...                        ...     ...         ...   \n",
      "9995  449452    bjspringer@jonesday.com  449405  08/11/2000   \n",
      "9996  349257       kate.symes@enron.com  348176  30/03/2001   \n",
      "9997  430195  courtnie.parker@enron.com  430050  14/05/2001   \n",
      "9998  280639    jeff.dasovich@enron.com  278851  22/08/2001   \n",
      "9999  100291    jeff.dasovich@enron.com   98475  16/02/2001   \n",
      "\n",
      "                                         message_id  \\\n",
      "0     <13856275.1075854158988.JavaMail.evans@thyme>   \n",
      "1     <13282917.1075842132788.JavaMail.evans@thyme>   \n",
      "2        <80709.1075853802377.JavaMail.evans@thyme>   \n",
      "3      <4732369.1075855007491.JavaMail.evans@thyme>   \n",
      "4      <2150475.1075840868873.JavaMail.evans@thyme>   \n",
      "...                                             ...   \n",
      "9995  <32224251.1075845879208.JavaMail.evans@thyme>   \n",
      "9996  <11683795.1075841903088.JavaMail.evans@thyme>   \n",
      "9997  <26606938.1075848339340.JavaMail.evans@thyme>   \n",
      "9998  <23963209.1075840897619.JavaMail.evans@thyme>   \n",
      "9999   <3968603.1075843853121.JavaMail.evans@thyme>   \n",
      "\n",
      "                                         subject  \\\n",
      "0                            Re: Midcon Invoices   \n",
      "1                             Birth Announcement   \n",
      "2                       East Tennessee Nora Rate   \n",
      "3                FW: Contacts for West End Teams   \n",
      "4         FW: GLOBAL PERFORMANCE MANAGEMENT YE01   \n",
      "...                                          ...   \n",
      "9995             RE: PGL/enovate Master Contract   \n",
      "9996                           Re: 3/30 Checkout   \n",
      "9997               Alexander McElreath-Real time   \n",
      "9998                  California Update 08.22.01   \n",
      "9999  Legislative Status Report Week Ending 2/16   \n",
      "\n",
      "                                                   body               folder  \\\n",
      "0     I know we transported on Midcon due to problem...                 sent   \n",
      "1     Terry:\\nJust wanted to let you know that our s...                 sent   \n",
      "2     ---------------------- Forwarded by Chris Germ...                 sent   \n",
      "3     FYI, Kim.\\n\\n -----Original Message-----\\nFrom...  tw_commercial_group   \n",
      "4     -----Original Message-----\\nFrom: \\tMujica, Mi...            _americas   \n",
      "...                                                 ...                  ...   \n",
      "9995  I received the attached revised testimony and ...              enovate   \n",
      "9996  It's been changed to 250 - Chris is going to t...                 sent   \n",
      "9997  Don,\\nPlease advise of your interest in the fo...                power   \n",
      "9998  Though announced yesterday that Davis and the ...            _americas   \n",
      "9999  ----- Forwarded by Jeff Dasovich/NA/Enron on 0...                 sent   \n",
      "\n",
      "      length_character  length_word  \\\n",
      "0                 1244          188   \n",
      "1                  486           88   \n",
      "2                  288           34   \n",
      "3                 1003          152   \n",
      "4                 3015          388   \n",
      "...                ...          ...   \n",
      "9995              3257          436   \n",
      "9996               582           99   \n",
      "9997               125           16   \n",
      "9998              2041          333   \n",
      "9999              7498         1009   \n",
      "\n",
      "                                             body_clean  \\\n",
      "0     I know we transported on Midcon due to problem...   \n",
      "1     Terry:\\nJust wanted to let you know that our s...   \n",
      "2     ---------------------- Forwarded by Chris Germ...   \n",
      "3     FYI, Kim.\\n\\nPer our conversation this afterno...   \n",
      "4     FYI!\\n\\nIt has been decided that given current...   \n",
      "...                                                 ...   \n",
      "9995  I received the attached revised testimony and ...   \n",
      "9996  It's been changed to 250 - Chris is going to t...   \n",
      "9997  Don,\\nPlease advise of your interest in the fo...   \n",
      "9998  Though announced yesterday that Davis and the ...   \n",
      "9999  ----- Forwarded by Jeff Dasovich/NA/Enron on 0...   \n",
      "\n",
      "      clean_length_character  clean_length_word  similarities  \n",
      "0                        951                156      0.849883  \n",
      "1                        485                 88      0.800148  \n",
      "2                        215                 26      0.795585  \n",
      "3                        845                131      0.859175  \n",
      "4                        376                 58      0.752676  \n",
      "...                      ...                ...           ...  \n",
      "9995                    2713                390      0.827284  \n",
      "9996                     511                 92      0.771932  \n",
      "9997                     123                 16      0.654586  \n",
      "9998                    2039                333      0.745477  \n",
      "9999                    7144                970      0.726361  \n",
      "\n",
      "[10000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70de2497",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_queries = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_query_and_ed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/pandas/core/frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_queries = df.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalculate_query_and_ed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mcalculate_query_and_ed\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_query_and_ed\u001b[39m(row):\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# try: \u001b[39;00m\n\u001b[32m     24\u001b[39m         text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mbody_clean\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         row[\u001b[33m'\u001b[39m\u001b[33mtext_rank_query\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43msummarizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m     28\u001b[39m         \u001b[38;5;66;03m# --- 2. Generate \"Elaborative Description\" (Keyword Extraction) ---\u001b[39;00m\n\u001b[32m     29\u001b[39m         \u001b[38;5;66;03m# We want a list of salient terms that describe the document content.\u001b[39;00m\n\u001b[32m     30\u001b[39m         \u001b[38;5;66;03m# This creates a \"bag of entities\" representation useful for GR.\u001b[39;00m\n\u001b[32m     31\u001b[39m         \u001b[38;5;66;03m# row['elaborative_description'] = keywords.keywords(text, words=8)\u001b[39;00m\n\u001b[32m     32\u001b[39m         row[\u001b[33m'\u001b[39m\u001b[33melaborative_description\u001b[39m\u001b[33m'\u001b[39m] = get_keywords_safe(text, \u001b[32m8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/summa/summarizer.py:131\u001b[39m, in \u001b[36msummarize\u001b[39m\u001b[34m(text, ratio, words, language, split, scores, additional_stopwords)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [] \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Ranks the tokens using the PageRank algorithm. Returns dict of sentence -> score\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m pagerank_scores = \u001b[43m_pagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Adds the summa scores to the sentence objects.\u001b[39;00m\n\u001b[32m    134\u001b[39m _add_scores_to_sentences(sentences, pagerank_scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/summa/pagerank_weighted.py:46\u001b[39m, in \u001b[36mpagerank_weighted_scipy\u001b[39m\u001b[34m(graph, damping)\u001b[39m\n\u001b[32m     43\u001b[39m probability_matrix = build_probability_matrix(graph)\n\u001b[32m     45\u001b[39m pagerank_matrix = damping * adjacency_matrix.todense() + (\u001b[32m1\u001b[39m - damping) * probability_matrix\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m vals, vecs = \u001b[43meig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerank_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m process_results(graph, vecs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/scipy/_lib/_util.py:1233\u001b[39m, in \u001b[36m_apply_over_batch.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;66;03m# Early exit if call is not batched\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(batch_shapes):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mother_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[38;5;66;03m# Determine broadcasted batch shape\u001b[39;00m\n\u001b[32m   1236\u001b[39m batch_shape = np.broadcast_shapes(*batch_shapes)  \u001b[38;5;66;03m# Gives OK error message\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uva/bachelor_ki/bep/code/.venv/lib/python3.13/site-packages/scipy/linalg/_decomp.py:257\u001b[39m, in \u001b[36meig\u001b[39m\u001b[34m(a, b, left, right, overwrite_a, overwrite_b, check_finite, homogeneous_eigvals)\u001b[39m\n\u001b[32m    255\u001b[39m     w = _make_eigvals(w, \u001b[38;5;28;01mNone\u001b[39;00m, homogeneous_eigvals)\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     wr, wi, vl, vr, info = \u001b[43mgeev\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mcompute_vl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_vl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mcompute_vr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_vr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                                \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m     w = wr + _I * wi\n\u001b[32m    262\u001b[39m     w = _make_eigvals(w, \u001b[38;5;28;01mNone\u001b[39;00m, homogeneous_eigvals)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_queries = df.apply(lambda x: calculate_query_and_ed(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9783018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dan just dumped me, so we can go any where you want.  Do you have a \n",
      "preference?\n",
      "Kay\n",
      "\n",
      "see you then\n"
     ]
    }
   ],
   "source": [
    "df['char_count'] = df['body_clean'].str.len()\n",
    "\n",
    "# Sort from short to long\n",
    "df_sorted = df.sort_values(by='char_count', ascending=True)\n",
    "\n",
    "# Display result\n",
    "print(df_sorted.iloc[3]['body_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a32fdb",
   "metadata": {},
   "source": [
    "todo: queries\n",
    "and queries transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fca438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Write to new table 'similarities'\n",
    "# if_exists='replace' drops the table if it exists and creates a new one\n",
    "# if_exists='append' adds to it\n",
    "df.to_sql(\n",
    "    name='N10k_text_rank',\n",
    "    con=conn,\n",
    "    if_exists='replace', \n",
    "    index=False,\n",
    "    chunksize=10000  # Write in batches to save memory\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_sim_mid ON Message (mid)\")\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
